{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Do', 'you', 'know', 'what', 'separates', 'humans', 'from', 'other', 'living', 'beings', '?', 'Curiosity', ',', 'Humans', 'are', 'curious.We', 'have', 'a', 'collection', 'of', 'question', 'on', 'our', 'pleasant', 'past', ',', 'beautiful', 'present', 'and', 'bright', 'future.We', 'are', 'curious', 'to', 'take', 'challenges', '.', 'So', 'When', 'we', 'think', 'about', 'our', 'Future', 'a', 'pic', 'of', 'Smart', 'Gadgets', 'comes', 'in', 'front', 'of', 'us', '.', 'We', '’', 've', 'been', 'fascinated', 'with', 'gadgets', 'that', 'Function', 'on', 'a', 'grander', 'scale', 'for', 'decades', 'which', 'we', 'usually', 'see', 'in', 'Hollywood', 'movies.So', 'now', 'the', 'point', 'comes', ',', '‘', 'Is', 'it', 'possible', 'to', 'do', ',', 'what', 'is', 'the', 'way', 'to', 'make', 'our', 'dreams', 'real', 'in', 'future', '’', '.', 'But', 'in', 'the', 'past', 'several', 'years', 'we', '’', 've', 'seen', 'the', 'True', 'Potential', 'of', 'the', 'IoT', 'which', 'show', 'as', 'a', 'path', 'towards', 'our', 'dreams', 'and', 'open', 'the', 'way', 'to', 'future', 'of', 'technology', '.']\n",
      "['Do', 'know', 'separates', 'humans', 'living', 'beings', '?', 'Curiosity', ',', 'Humans', 'curious.We', 'collection', 'question', 'pleasant', 'past', ',', 'beautiful', 'present', 'bright', 'future.We', 'curious', 'take', 'challenges', '.', 'So', 'When', 'think', 'Future', 'pic', 'Smart', 'Gadgets', 'comes', 'front', 'us', '.', 'We', '’', 'fascinated', 'gadgets', 'Function', 'grander', 'scale', 'decades', 'usually', 'see', 'Hollywood', 'movies.So', 'point', 'comes', ',', '‘', 'Is', 'possible', ',', 'way', 'make', 'dreams', 'real', 'future', '’', '.', 'But', 'past', 'several', 'years', '’', 'seen', 'True', 'Potential', 'IoT', 'show', 'path', 'towards', 'dreams', 'open', 'way', 'future', 'technology', '.']\n",
      "              1    2    3    4    5\n",
      ",           NaN  2.0  NaN  2.0  NaN\n",
      ".           NaN  1.0  1.0  1.0  1.0\n",
      "?           1.0  NaN  NaN  NaN  NaN\n",
      "But         NaN  NaN  NaN  NaN  1.0\n",
      "Curiosity   NaN  1.0  NaN  NaN  NaN\n",
      "Do          1.0  NaN  NaN  NaN  NaN\n",
      "Function    NaN  NaN  NaN  1.0  NaN\n",
      "Future      NaN  NaN  1.0  NaN  NaN\n",
      "Gadgets     NaN  NaN  1.0  NaN  NaN\n",
      "Hollywood   NaN  NaN  NaN  1.0  NaN\n",
      "Humans      NaN  1.0  NaN  NaN  NaN\n",
      "IoT         NaN  NaN  NaN  NaN  1.0\n",
      "Is          NaN  NaN  NaN  1.0  NaN\n",
      "Potential   NaN  NaN  NaN  NaN  1.0\n",
      "Smart       NaN  NaN  1.0  NaN  NaN\n",
      "So          NaN  NaN  1.0  NaN  NaN\n",
      "True        NaN  NaN  NaN  NaN  1.0\n",
      "We          NaN  NaN  NaN  1.0  NaN\n",
      "When        NaN  NaN  1.0  NaN  NaN\n",
      "a           NaN  1.0  1.0  1.0  1.0\n",
      "about       NaN  NaN  1.0  NaN  NaN\n",
      "and         NaN  1.0  NaN  NaN  1.0\n",
      "are         NaN  2.0  NaN  NaN  NaN\n",
      "as          NaN  NaN  NaN  NaN  1.0\n",
      "beautiful   NaN  1.0  NaN  NaN  NaN\n",
      "been        NaN  NaN  NaN  1.0  NaN\n",
      "beings      1.0  NaN  NaN  NaN  NaN\n",
      "bright      NaN  1.0  NaN  NaN  NaN\n",
      "challenges  NaN  1.0  NaN  NaN  NaN\n",
      "collection  NaN  1.0  NaN  NaN  NaN\n",
      "...         ...  ...  ...  ...  ...\n",
      "point       NaN  NaN  NaN  1.0  NaN\n",
      "possible    NaN  NaN  NaN  1.0  NaN\n",
      "present     NaN  1.0  NaN  NaN  NaN\n",
      "question    NaN  1.0  NaN  NaN  NaN\n",
      "real        NaN  NaN  NaN  1.0  NaN\n",
      "scale       NaN  NaN  NaN  1.0  NaN\n",
      "see         NaN  NaN  NaN  1.0  NaN\n",
      "seen        NaN  NaN  NaN  NaN  1.0\n",
      "separates   1.0  NaN  NaN  NaN  NaN\n",
      "several     NaN  NaN  NaN  NaN  1.0\n",
      "show        NaN  NaN  NaN  NaN  1.0\n",
      "take        NaN  1.0  NaN  NaN  NaN\n",
      "technology  NaN  NaN  NaN  NaN  1.0\n",
      "that        NaN  NaN  NaN  1.0  NaN\n",
      "the         NaN  NaN  NaN  2.0  4.0\n",
      "think       NaN  NaN  1.0  NaN  NaN\n",
      "to          NaN  1.0  NaN  2.0  1.0\n",
      "towards     NaN  NaN  NaN  NaN  1.0\n",
      "us          NaN  NaN  1.0  NaN  NaN\n",
      "usually     NaN  NaN  NaN  1.0  NaN\n",
      "ve          NaN  NaN  NaN  1.0  1.0\n",
      "way         NaN  NaN  NaN  1.0  1.0\n",
      "we          NaN  NaN  1.0  1.0  1.0\n",
      "what        1.0  NaN  NaN  1.0  NaN\n",
      "which       NaN  NaN  NaN  1.0  1.0\n",
      "with        NaN  NaN  NaN  1.0  NaN\n",
      "years       NaN  NaN  NaN  NaN  1.0\n",
      "you         1.0  NaN  NaN  NaN  NaN\n",
      "‘           NaN  NaN  NaN  1.0  NaN\n",
      "’           NaN  NaN  NaN  2.0  1.0\n",
      "\n",
      "[93 rows x 5 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ganpa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ganpa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "data = \"\"\"\n",
    "Do you know what separates humans from other living beings? Curiosity,\n",
    "Humans are curious.We have a collection of question on our pleasant past,\n",
    "beautiful present and bright future.We are curious to take challenges.\n",
    "So When we think about our Future a pic of Smart Gadgets comes in front of us. \n",
    "We’ve been fascinated with gadgets that Function on a grander scale for decades\n",
    "which we usually see in Hollywood movies.So now the point comes, \n",
    "‘Is it possible to do,what is the way to make our dreams real in future’.\n",
    "But in the past several years we’ve seen the True Potential of the IoT \n",
    "which show as a path towards our dreams and open the way to future of technology.\n",
    "\"\"\"\n",
    "word_tokens=word_tokenize(data)\n",
    "sent_tokens = sent_tokenize(data)\n",
    "stop_words = set(stopwords.words('English')) \n",
    "print(word_tokens)\n",
    "#print(sent_tokens)\n",
    "\n",
    "filtered_data = [i for i in word_tokens if not i in stop_words] \n",
    "  \n",
    "filtered_data = [] \n",
    "  \n",
    "for i in word_tokens: \n",
    "    if i not in stop_words: \n",
    "        filtered_data.append(i) \n",
    "print(filtered_data) \n",
    "\n",
    "paracount = dict()\n",
    "k=1\n",
    "for line in sent_tokens:\n",
    "    wordtokens = word_tokenize(line)\n",
    "    linecount = len(sent_tokens)\n",
    "    count = dict()\n",
    "    for word in wordtokens:\n",
    "        if word in count:\n",
    "            count[word] +=1\n",
    "        else:\n",
    "            count[word] = 1\n",
    "    paracount[k] = count\n",
    "    k+=1\n",
    "#print(paracount)\n",
    "pdf = pd.DataFrame(paracount)\n",
    "print(pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Do', 'know', 'separates', 'humans', 'living', 'beings', '?', 'Curiosity', ',', 'Humans', 'curious.We', 'collection', 'question', 'pleasant', 'past', ',', 'beautiful', 'present', 'bright', 'future.We', 'curious', 'take', 'challenges', '.', 'So', 'When', 'think', 'Future', 'pic', 'Smart', 'Gadgets', 'comes', 'front', 'us', '.', 'We', '’', 'fascinated', 'gadgets', 'Function', 'grander', 'scale', 'decades', 'usually', 'see', 'Hollywood', 'movies.So', 'point', 'comes', ',', '‘', 'Is', 'possible', ',', 'way', 'make', 'dreams', 'real', 'future', '’', '.', 'But', 'past', 'several', 'years', '’', 'seen', 'True', 'Potential', 'IoT', 'show', 'path', 'towards', 'dreams', 'open', 'way', 'future', 'technology', '.']\n"
     ]
    }
   ],
   "source": [
    "filtered_data = [i for i in word_tokens if not i in stop_words] \n",
    "  \n",
    "filtered_data = [] \n",
    "  \n",
    "for i in word_tokens: \n",
    "    if i not in stop_words: \n",
    "        filtered_data.append(i) \n",
    "print(filtered_data) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
